{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml\n",
    "from doubleml.datasets import fetch_401K\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import causalml\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_401K(return_type='DataFrame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into two equal groups ensuring that e401 is equally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1: \n",
      " 0    3131\n",
      "1    1827\n",
      "Name: e401, dtype: int64\n",
      "df2: \n",
      " 0    3102\n",
      "1    1855\n",
      "Name: e401, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "df1 = data.sample(frac = 0.5)\n",
    "df2 = data.drop(df1.index)\n",
    "\n",
    "print('df1: \\n', df1['e401'].value_counts())\n",
    "print('df2: \\n', df2['e401'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get subdataframes separated by eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_0 = df1.loc[df1['e401'] == 0]\n",
    "df1_1 = df1.loc[df1['e401'] == 1]\n",
    "df2_0 = df2.loc[df2['e401'] == 0]\n",
    "df2_1 = df2.loc[df2['e401'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nifa       False\n",
      "net_tfa    False\n",
      "tw         False\n",
      "age        False\n",
      "inc        False\n",
      "fsize      False\n",
      "educ       False\n",
      "db         False\n",
      "marr       False\n",
      "twoearn    False\n",
      "e401       False\n",
      "p401       False\n",
      "pira       False\n",
      "hown       False\n",
      "dtype: bool\n",
      "nifa       False\n",
      "net_tfa    False\n",
      "tw         False\n",
      "age        False\n",
      "inc        False\n",
      "fsize      False\n",
      "educ       False\n",
      "db         False\n",
      "marr       False\n",
      "twoearn    False\n",
      "e401       False\n",
      "p401       False\n",
      "pira       False\n",
      "hown       False\n",
      "dtype: bool\n",
      "nifa       False\n",
      "net_tfa    False\n",
      "tw         False\n",
      "age        False\n",
      "inc        False\n",
      "fsize      False\n",
      "educ       False\n",
      "db         False\n",
      "marr       False\n",
      "twoearn    False\n",
      "e401       False\n",
      "p401       False\n",
      "pira       False\n",
      "hown       False\n",
      "dtype: bool\n",
      "nifa       False\n",
      "net_tfa    False\n",
      "tw         False\n",
      "age        False\n",
      "inc        False\n",
      "fsize      False\n",
      "educ       False\n",
      "db         False\n",
      "marr       False\n",
      "twoearn    False\n",
      "e401       False\n",
      "p401       False\n",
      "pira       False\n",
      "hown       False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "for i in [df1_0, df1_1, df2_0, df2_1]:\n",
    "    print(i.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train two models, one for D1_1, and another for D1_0, f1 and f0, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DoubleML backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up basic model: Specify variables for data-backend\n",
    "features_base = ['age', 'inc', 'educ', 'fsize', 'marr',\n",
    "                 'twoearn', 'db', 'pira', 'hown']\n",
    "\n",
    "# Initialize DoubleMLData (data-backend of DoubleML)\n",
    "data_dml_base = dml.DoubleMLData(data,\n",
    "                                 y_col='net_tfa',\n",
    "                                 d_cols='e401',\n",
    "                                 x_cols=features_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df1_0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a model according to regression formula with polynomials\n",
    "features = df1_0.copy()[['marr', 'twoearn', 'db', 'pira', 'hown']]\n",
    "\n",
    "poly_dict = {'age': 2,\n",
    "             'inc': 2,\n",
    "             'educ': 2,\n",
    "             'fsize': 2}\n",
    "for key, degree in poly_dict.items():\n",
    "    poly = PolynomialFeatures(degree, include_bias=False)\n",
    "    data_transf = poly.fit_transform(df1_0[[key]])\n",
    "    x_cols = poly.get_feature_names_out([key])\n",
    "    data_transf = pd.DataFrame(data_transf, columns=x_cols)\n",
    "\n",
    "    features = pd.concat((features, data_transf),\n",
    "                          axis=1, sort=False)\n",
    "\n",
    "df1_0_model_data = pd.concat((df1_0.copy()[['net_tfa', 'e401']], features.copy()),\n",
    "                        axis=1, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marr       False\n",
       "twoearn    False\n",
       "db         False\n",
       "pira       False\n",
       "hown       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df1_1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4fddbfe8d809e2d3e9162ef69ab0c6689347e519fade92586b6599260d81fd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
